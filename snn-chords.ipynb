{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import sklearn\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow import keras\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in data\n",
    "\n",
    "in_file_path_chords = os.path.join(os.getcwd(), 'Data//Chords', 'input.txt')\n",
    "out_file_path_chords = os.path.join(os.getcwd(), 'Data//Chords', 'output.txt')\n",
    "\n",
    "in_file_path_isolated = os.path.join(os.getcwd(), 'Data//Isolated', 'input.txt')\n",
    "out_file_path_isolated = os.path.join(os.getcwd(), 'Data//Isolated', 'output.txt')\n",
    "\n",
    "inp_chords = pd.read_csv(in_file_path_chords,sep=\"\t\",header=None)\n",
    "out_chords = pd.read_csv(out_file_path_chords,sep=\"\t\",header=None)\n",
    "\n",
    "inp_isolated = pd.read_csv(in_file_path_isolated,sep=\"\t\",header=None)\n",
    "out_isolated = pd.read_csv(out_file_path_isolated,sep=\"\t\",header=None)\n",
    "\n",
    "inp = pd.concat([inp_chords,inp_isolated],axis=0,ignore_index=True)\n",
    "out = pd.concat([out_chords,out_isolated],axis=0,ignore_index=True)\n",
    "out_save = out.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "out=out_save.copy()\n",
    "a=out.copy()\n",
    "b=out.copy()\n",
    "a=a.iloc[:,0:88]\n",
    "b=b.iloc[:,100]\n",
    "out=pd.concat([a,b],axis=1,ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>386</th>\n",
       "      <th>387</th>\n",
       "      <th>388</th>\n",
       "      <th>389</th>\n",
       "      <th>390</th>\n",
       "      <th>391</th>\n",
       "      <th>392</th>\n",
       "      <th>393</th>\n",
       "      <th>394</th>\n",
       "      <th>395</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.812025</td>\n",
       "      <td>1.624050</td>\n",
       "      <td>1.624050</td>\n",
       "      <td>3.913080</td>\n",
       "      <td>3.913080</td>\n",
       "      <td>3.913080</td>\n",
       "      <td>3.913080</td>\n",
       "      <td>3.913080</td>\n",
       "      <td>3.913080</td>\n",
       "      <td>...</td>\n",
       "      <td>1.106185</td>\n",
       "      <td>0.858407</td>\n",
       "      <td>0.847096</td>\n",
       "      <td>0.793684</td>\n",
       "      <td>0.778737</td>\n",
       "      <td>0.748067</td>\n",
       "      <td>0.724419</td>\n",
       "      <td>0.706611</td>\n",
       "      <td>0.686300</td>\n",
       "      <td>0.662116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1.418441</td>\n",
       "      <td>2.836882</td>\n",
       "      <td>2.836882</td>\n",
       "      <td>4.859394</td>\n",
       "      <td>4.859394</td>\n",
       "      <td>4.859394</td>\n",
       "      <td>4.859394</td>\n",
       "      <td>4.859394</td>\n",
       "      <td>4.859394</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.025381</td>\n",
       "      <td>0.409624</td>\n",
       "      <td>0.221173</td>\n",
       "      <td>0.071951</td>\n",
       "      <td>0.036677</td>\n",
       "      <td>-0.037756</td>\n",
       "      <td>-0.045958</td>\n",
       "      <td>-0.132260</td>\n",
       "      <td>-0.132902</td>\n",
       "      <td>-0.205372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1.941972</td>\n",
       "      <td>3.883943</td>\n",
       "      <td>3.883943</td>\n",
       "      <td>3.923695</td>\n",
       "      <td>3.923695</td>\n",
       "      <td>3.923695</td>\n",
       "      <td>3.923695</td>\n",
       "      <td>3.923695</td>\n",
       "      <td>3.923695</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.823510</td>\n",
       "      <td>-0.783446</td>\n",
       "      <td>-0.680334</td>\n",
       "      <td>-0.707531</td>\n",
       "      <td>-0.660219</td>\n",
       "      <td>-0.635870</td>\n",
       "      <td>-0.607445</td>\n",
       "      <td>-0.481730</td>\n",
       "      <td>-0.491079</td>\n",
       "      <td>-0.412551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1.519993</td>\n",
       "      <td>3.039987</td>\n",
       "      <td>3.039987</td>\n",
       "      <td>3.752422</td>\n",
       "      <td>3.752422</td>\n",
       "      <td>3.752422</td>\n",
       "      <td>3.752422</td>\n",
       "      <td>3.752422</td>\n",
       "      <td>3.752422</td>\n",
       "      <td>...</td>\n",
       "      <td>0.069886</td>\n",
       "      <td>-0.022846</td>\n",
       "      <td>-0.014781</td>\n",
       "      <td>0.056528</td>\n",
       "      <td>0.041726</td>\n",
       "      <td>0.100550</td>\n",
       "      <td>0.107269</td>\n",
       "      <td>0.041530</td>\n",
       "      <td>0.060296</td>\n",
       "      <td>0.072066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0.768128</td>\n",
       "      <td>1.536256</td>\n",
       "      <td>1.536256</td>\n",
       "      <td>1.963922</td>\n",
       "      <td>1.963922</td>\n",
       "      <td>1.963922</td>\n",
       "      <td>1.963922</td>\n",
       "      <td>1.963922</td>\n",
       "      <td>1.963922</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.043950</td>\n",
       "      <td>-0.141456</td>\n",
       "      <td>-0.074712</td>\n",
       "      <td>0.032988</td>\n",
       "      <td>0.067159</td>\n",
       "      <td>0.063161</td>\n",
       "      <td>0.052910</td>\n",
       "      <td>0.093240</td>\n",
       "      <td>0.086584</td>\n",
       "      <td>0.090886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.242890</td>\n",
       "      <td>1.242890</td>\n",
       "      <td>1.242890</td>\n",
       "      <td>1.242890</td>\n",
       "      <td>1.242890</td>\n",
       "      <td>1.242890</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.157488</td>\n",
       "      <td>-0.188632</td>\n",
       "      <td>-0.160135</td>\n",
       "      <td>-0.089689</td>\n",
       "      <td>-0.118595</td>\n",
       "      <td>-0.101636</td>\n",
       "      <td>-0.097888</td>\n",
       "      <td>-0.102011</td>\n",
       "      <td>-0.070883</td>\n",
       "      <td>-0.077959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0.032415</td>\n",
       "      <td>0.064830</td>\n",
       "      <td>0.064830</td>\n",
       "      <td>0.245909</td>\n",
       "      <td>0.245909</td>\n",
       "      <td>0.245909</td>\n",
       "      <td>0.245909</td>\n",
       "      <td>0.245909</td>\n",
       "      <td>0.245909</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.010176</td>\n",
       "      <td>-0.007416</td>\n",
       "      <td>-0.002725</td>\n",
       "      <td>-0.026662</td>\n",
       "      <td>0.011976</td>\n",
       "      <td>0.008913</td>\n",
       "      <td>-0.016778</td>\n",
       "      <td>0.013893</td>\n",
       "      <td>0.017804</td>\n",
       "      <td>0.014665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.226729</td>\n",
       "      <td>0.226729</td>\n",
       "      <td>0.226729</td>\n",
       "      <td>0.226729</td>\n",
       "      <td>0.226729</td>\n",
       "      <td>0.226729</td>\n",
       "      <td>...</td>\n",
       "      <td>0.046430</td>\n",
       "      <td>0.040876</td>\n",
       "      <td>0.035996</td>\n",
       "      <td>0.033969</td>\n",
       "      <td>-0.000022</td>\n",
       "      <td>0.007236</td>\n",
       "      <td>0.039297</td>\n",
       "      <td>0.010850</td>\n",
       "      <td>0.003968</td>\n",
       "      <td>0.012074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015566</td>\n",
       "      <td>0.015566</td>\n",
       "      <td>0.015566</td>\n",
       "      <td>0.015566</td>\n",
       "      <td>0.015566</td>\n",
       "      <td>0.015566</td>\n",
       "      <td>...</td>\n",
       "      <td>0.038984</td>\n",
       "      <td>0.023695</td>\n",
       "      <td>0.016702</td>\n",
       "      <td>0.024266</td>\n",
       "      <td>0.033282</td>\n",
       "      <td>0.008172</td>\n",
       "      <td>0.027050</td>\n",
       "      <td>0.022300</td>\n",
       "      <td>0.020181</td>\n",
       "      <td>0.009479</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 396 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0         1         2         3         4         5         6         7    \\\n",
       "0    0  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "1    0  0.812025  1.624050  1.624050  3.913080  3.913080  3.913080  3.913080   \n",
       "2    0  1.418441  2.836882  2.836882  4.859394  4.859394  4.859394  4.859394   \n",
       "3    0  1.941972  3.883943  3.883943  3.923695  3.923695  3.923695  3.923695   \n",
       "4    0  1.519993  3.039987  3.039987  3.752422  3.752422  3.752422  3.752422   \n",
       "5    0  0.768128  1.536256  1.536256  1.963922  1.963922  1.963922  1.963922   \n",
       "6    0  0.000000  0.000000  0.000000  1.242890  1.242890  1.242890  1.242890   \n",
       "7    0  0.032415  0.064830  0.064830  0.245909  0.245909  0.245909  0.245909   \n",
       "8    0  0.000000  0.000000  0.000000  0.226729  0.226729  0.226729  0.226729   \n",
       "9    0  0.000000  0.000000  0.000000  0.015566  0.015566  0.015566  0.015566   \n",
       "\n",
       "        8         9      ...          386       387       388       389  \\\n",
       "0  0.000000  0.000000    ...     0.000000  0.000000  0.000000  0.000000   \n",
       "1  3.913080  3.913080    ...     1.106185  0.858407  0.847096  0.793684   \n",
       "2  4.859394  4.859394    ...    -0.025381  0.409624  0.221173  0.071951   \n",
       "3  3.923695  3.923695    ...    -0.823510 -0.783446 -0.680334 -0.707531   \n",
       "4  3.752422  3.752422    ...     0.069886 -0.022846 -0.014781  0.056528   \n",
       "5  1.963922  1.963922    ...    -0.043950 -0.141456 -0.074712  0.032988   \n",
       "6  1.242890  1.242890    ...    -0.157488 -0.188632 -0.160135 -0.089689   \n",
       "7  0.245909  0.245909    ...    -0.010176 -0.007416 -0.002725 -0.026662   \n",
       "8  0.226729  0.226729    ...     0.046430  0.040876  0.035996  0.033969   \n",
       "9  0.015566  0.015566    ...     0.038984  0.023695  0.016702  0.024266   \n",
       "\n",
       "        390       391       392       393       394       395  \n",
       "0  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "1  0.778737  0.748067  0.724419  0.706611  0.686300  0.662116  \n",
       "2  0.036677 -0.037756 -0.045958 -0.132260 -0.132902 -0.205372  \n",
       "3 -0.660219 -0.635870 -0.607445 -0.481730 -0.491079 -0.412551  \n",
       "4  0.041726  0.100550  0.107269  0.041530  0.060296  0.072066  \n",
       "5  0.067159  0.063161  0.052910  0.093240  0.086584  0.090886  \n",
       "6 -0.118595 -0.101636 -0.097888 -0.102011 -0.070883 -0.077959  \n",
       "7  0.011976  0.008913 -0.016778  0.013893  0.017804  0.014665  \n",
       "8 -0.000022  0.007236  0.039297  0.010850  0.003968  0.012074  \n",
       "9  0.033282  0.008172  0.027050  0.022300  0.020181  0.009479  \n",
       "\n",
       "[10 rows x 396 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(inp.iloc[0:10,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>79</th>\n",
       "      <th>80</th>\n",
       "      <th>81</th>\n",
       "      <th>82</th>\n",
       "      <th>83</th>\n",
       "      <th>84</th>\n",
       "      <th>85</th>\n",
       "      <th>86</th>\n",
       "      <th>87</th>\n",
       "      <th>88</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 89 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0   1   2   3   4   5   6   7   8   9  ...  79  80  81  82  83  84  85  86  \\\n",
       "0   0   0   0   0   0   0   0   0   0   0 ...   0   0   0   0   0   0   0   0   \n",
       "1   0   0   0   0   0   0   0   0   0   0 ...   0   0   0   0   0   0   0   0   \n",
       "2   0   0   0   0   0   0   0   0   0   0 ...   0   0   0   0   0   0   0   0   \n",
       "3   0   0   0   0   0   0   0   0   1   0 ...   0   0   0   0   0   0   0   0   \n",
       "4   0   0   0   0   0   0   0   0   1   0 ...   0   0   0   0   0   0   0   0   \n",
       "5   0   0   0   0   0   0   0   0   1   0 ...   0   0   0   0   0   0   0   0   \n",
       "6   0   0   0   0   0   0   0   0   0   0 ...   0   0   0   0   0   0   0   0   \n",
       "7   0   0   0   0   0   0   0   0   0   0 ...   0   0   0   0   0   0   0   0   \n",
       "8   0   0   0   0   0   0   0   0   0   0 ...   0   0   0   0   0   0   0   0   \n",
       "9   0   0   0   0   0   0   0   0   0   0 ...   0   0   0   0   0   0   0   0   \n",
       "\n",
       "   87  88  \n",
       "0   0   1  \n",
       "1   0   1  \n",
       "2   0   1  \n",
       "3   0   0  \n",
       "4   0   0  \n",
       "5   0   0  \n",
       "6   0   1  \n",
       "7   0   1  \n",
       "8   0   1  \n",
       "9   0   1  \n",
       "\n",
       "[10 rows x 89 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(out.iloc[0:10,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get some info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty instances: 26370\n",
      "Not empty instances: 12740\n"
     ]
    }
   ],
   "source": [
    "count_empty = np.sum(out.iloc[:,out.shape[1]-1],axis=0)\n",
    "count_not_empty = out.shape[0] - count_empty\n",
    "print('Empty instances:',count_empty)\n",
    "print('Not empty instances:',count_not_empty)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>86</th>\n",
       "      <th>87</th>\n",
       "      <th>88</th>\n",
       "      <th>89</th>\n",
       "      <th>90</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 96 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0   1   2   3   4   5   6   7   8   9  ...  86  87  88  89  90  91  92  93  \\\n",
       "0   0   0   0   0   0   0   0   0   0   0 ...   0   0   1   0   0   0   0   0   \n",
       "1   0   0   0   0   0   0   0   0   0   0 ...   0   0   1   0   0   0   0   0   \n",
       "2   0   0   0   0   0   0   0   0   0   0 ...   0   0   1   0   0   0   0   0   \n",
       "3   0   0   0   0   0   0   0   0   1   0 ...   0   0   0   0   1   0   0   0   \n",
       "4   0   0   0   0   0   0   0   0   1   0 ...   0   0   0   0   1   0   0   0   \n",
       "5   0   0   0   0   0   0   0   0   1   0 ...   0   0   0   0   1   0   0   0   \n",
       "6   0   0   0   0   0   0   0   0   0   0 ...   0   0   1   0   0   0   0   0   \n",
       "7   0   0   0   0   0   0   0   0   0   0 ...   0   0   1   0   0   0   0   0   \n",
       "8   0   0   0   0   0   0   0   0   0   0 ...   0   0   1   0   0   0   0   0   \n",
       "9   0   0   0   0   0   0   0   0   0   0 ...   0   0   1   0   0   0   0   0   \n",
       "\n",
       "   94  95  \n",
       "0   0   0  \n",
       "1   0   0  \n",
       "2   0   0  \n",
       "3   0   0  \n",
       "4   0   0  \n",
       "5   0   0  \n",
       "6   0   0  \n",
       "7   0   0  \n",
       "8   0   0  \n",
       "9   0   0  \n",
       "\n",
       "[10 rows x 96 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "only_notes=out.iloc[:,0:out.shape[1]-1]\n",
    "count_notes = np.sum(only_notes,axis=1)\n",
    "count_notes_hot = pd.get_dummies(count_notes)\n",
    "out_hot=pd.concat([only_notes,count_notes_hot],axis=1,ignore_index=True)\n",
    "display(out_hot.iloc[0:10,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "empty = out_hot.iloc[:,88].get_values()\n",
    "empty_idx = np.where(empty==1)[0]\n",
    "not_empty_idx = np.where(empty==0)[0]\n",
    "\n",
    "# How many empty?\n",
    "num_empty = 1000\n",
    "\n",
    "# Get random empty index\n",
    "ii = random.sample(range(0,empty_idx.shape[0]),num_empty)\n",
    "rand_empty_idx = empty_idx[ii]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f6497e7a2e8>]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(np.sum(out.iloc[:,0:out.shape[1]-1],axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39110,)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "empty.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_n shape: (10992, 396)\n",
      "y_train_n shape: (10992, 88)\n",
      "X_test_n shape: (2748, 396)\n",
      "y_test_n shape: (2748, 88)\n"
     ]
    }
   ],
   "source": [
    "# Split no note info\n",
    "X_n = pd.concat([inp.iloc[not_empty_idx,:],inp.iloc[rand_empty_idx,:]],axis=0,ignore_index=True)\n",
    "y_n = pd.concat([out.iloc[not_empty_idx,0:out.shape[1]-1],out.iloc[rand_empty_idx,0:out.shape[1]-1]],axis=0,ignore_index=True)\n",
    "X_train_n,X_test_n,y_train_n,y_test_n = train_test_split(X_n,y_n,train_size=0.80,test_size=0.20)\n",
    "print('X_train_n shape:',X_train_n.shape)\n",
    "print('y_train_n shape:',y_train_n.shape)\n",
    "print('X_test_n shape:',X_test_n.shape)\n",
    "print('y_test_n shape:',y_test_n.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_e shape: (10992, 396)\n",
      "y_train_e shape: (10992, 89)\n",
      "X_test_e shape: (2748, 396)\n",
      "y_test_e shape: (2748, 89)\n"
     ]
    }
   ],
   "source": [
    "# Split with empty\n",
    "X_e = pd.concat([inp.iloc[not_empty_idx,:],inp.iloc[rand_empty_idx,:]],axis=0,ignore_index=True)\n",
    "y_e = pd.concat([out.iloc[not_empty_idx,:],out.iloc[rand_empty_idx,:]],axis=0,ignore_index=True)\n",
    "X_train_e,X_test_e,y_train_e,y_test_e = train_test_split(X_e,y_e,train_size=0.80,test_size=0.20)\n",
    "print('X_train_e shape:',X_train_e.shape)\n",
    "print('y_train_e shape:',y_train_e.shape)\n",
    "print('X_test_e shape:',X_test_e.shape)\n",
    "print('y_test_e shape:',y_test_e.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_h shape: (10992, 396)\n",
      "y_train_h shape: (10992, 96)\n",
      "X_test_h shape: (2748, 396)\n",
      "y_test_h shape: (2748, 96)\n"
     ]
    }
   ],
   "source": [
    "# Split note one_hot\n",
    "X_h = pd.concat([inp.iloc[not_empty_idx,:],inp.iloc[rand_empty_idx,:]],axis=0,ignore_index=True)\n",
    "y_h = pd.concat([out_hot.iloc[not_empty_idx,:],out_hot.iloc[rand_empty_idx,:]],axis=0,ignore_index=True)\n",
    "X_train_h,X_test_h,y_train_h,y_test_h = train_test_split(X_h,y_h,train_size=0.80,test_size=0.20)\n",
    "print('X_train_h shape:',X_train_h.shape)\n",
    "print('y_train_h shape:',y_train_h.shape)\n",
    "print('X_test_h shape:',X_test_h.shape)\n",
    "print('y_test_h shape:',y_test_h.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "10992/10992 [==============================] - 1s 95us/step - loss: 8.9711 - acc: 0.0482\n",
      "Epoch 2/100\n",
      "10992/10992 [==============================] - 1s 70us/step - loss: 8.2202 - acc: 0.1748\n",
      "Epoch 3/100\n",
      "10992/10992 [==============================] - 1s 71us/step - loss: 7.3438 - acc: 0.3205\n",
      "Epoch 4/100\n",
      "10992/10992 [==============================] - 1s 78us/step - loss: 6.6553 - acc: 0.4184\n",
      "Epoch 5/100\n",
      "10992/10992 [==============================] - 1s 71us/step - loss: 6.1935 - acc: 0.4723\n",
      "Epoch 6/100\n",
      "10992/10992 [==============================] - 1s 70us/step - loss: 5.8475 - acc: 0.5073\n",
      "Epoch 7/100\n",
      "10992/10992 [==============================] - 1s 70us/step - loss: 5.5835 - acc: 0.5374\n",
      "Epoch 8/100\n",
      "10992/10992 [==============================] - 1s 85us/step - loss: 5.4041 - acc: 0.5443\n",
      "Epoch 9/100\n",
      "10992/10992 [==============================] - 1s 75us/step - loss: 5.2402 - acc: 0.5551\n",
      "Epoch 10/100\n",
      "10992/10992 [==============================] - 1s 73us/step - loss: 5.1123 - acc: 0.5620\n",
      "Epoch 11/100\n",
      "10992/10992 [==============================] - 1s 71us/step - loss: 4.9947 - acc: 0.5745\n",
      "Epoch 12/100\n",
      "10992/10992 [==============================] - 1s 74us/step - loss: 4.8897 - acc: 0.5716\n",
      "Epoch 13/100\n",
      "10992/10992 [==============================] - 1s 78us/step - loss: 4.8036 - acc: 0.5773\n",
      "Epoch 14/100\n",
      "10992/10992 [==============================] - 1s 82us/step - loss: 4.7327 - acc: 0.5781\n",
      "Epoch 15/100\n",
      "10992/10992 [==============================] - 1s 74us/step - loss: 4.6799 - acc: 0.5823\n",
      "Epoch 16/100\n",
      "10992/10992 [==============================] - 1s 72us/step - loss: 4.6120 - acc: 0.5848\n",
      "Epoch 17/100\n",
      "10992/10992 [==============================] - 1s 73us/step - loss: 4.5694 - acc: 0.5915\n",
      "Epoch 18/100\n",
      "10992/10992 [==============================] - 1s 73us/step - loss: 4.4995 - acc: 0.5952\n",
      "Epoch 19/100\n",
      "10992/10992 [==============================] - 1s 74us/step - loss: 4.4338 - acc: 0.5958\n",
      "Epoch 20/100\n",
      "10992/10992 [==============================] - 1s 72us/step - loss: 4.4002 - acc: 0.5978\n",
      "Epoch 21/100\n",
      "10992/10992 [==============================] - 1s 92us/step - loss: 4.3761 - acc: 0.6017\n",
      "Epoch 22/100\n",
      "10992/10992 [==============================] - 1s 93us/step - loss: 4.3357 - acc: 0.6097\n",
      "Epoch 23/100\n",
      "10992/10992 [==============================] - 1s 80us/step - loss: 4.2913 - acc: 0.6057\n",
      "Epoch 24/100\n",
      "10992/10992 [==============================] - 1s 84us/step - loss: 4.2795 - acc: 0.6107\n",
      "Epoch 25/100\n",
      "10992/10992 [==============================] - 1s 74us/step - loss: 4.2213 - acc: 0.6115\n",
      "Epoch 26/100\n",
      "10992/10992 [==============================] - 1s 73us/step - loss: 4.2030 - acc: 0.6086\n",
      "Epoch 27/100\n",
      "10992/10992 [==============================] - 1s 72us/step - loss: 4.1817 - acc: 0.6194\n",
      "Epoch 28/100\n",
      "10992/10992 [==============================] - 1s 82us/step - loss: 4.1576 - acc: 0.6161\n",
      "Epoch 29/100\n",
      "10992/10992 [==============================] - 1s 74us/step - loss: 4.0986 - acc: 0.6171\n",
      "Epoch 30/100\n",
      "10992/10992 [==============================] - 1s 75us/step - loss: 4.0734 - acc: 0.6126\n",
      "Epoch 31/100\n",
      "10992/10992 [==============================] - 1s 74us/step - loss: 4.0723 - acc: 0.6237\n",
      "Epoch 32/100\n",
      "10992/10992 [==============================] - 1s 81us/step - loss: 4.0473 - acc: 0.6134\n",
      "Epoch 33/100\n",
      "10992/10992 [==============================] - 1s 78us/step - loss: 4.0084 - acc: 0.6206\n",
      "Epoch 34/100\n",
      "10992/10992 [==============================] - 1s 75us/step - loss: 4.0182 - acc: 0.6255\n",
      "Epoch 35/100\n",
      "10992/10992 [==============================] - 1s 82us/step - loss: 4.0123 - acc: 0.6215\n",
      "Epoch 36/100\n",
      "10992/10992 [==============================] - 1s 111us/step - loss: 3.9767 - acc: 0.6234\n",
      "Epoch 37/100\n",
      "10992/10992 [==============================] - 1s 99us/step - loss: 3.9775 - acc: 0.6249\n",
      "Epoch 38/100\n",
      "10992/10992 [==============================] - 1s 61us/step - loss: 3.9485 - acc: 0.6264\n",
      "Epoch 39/100\n",
      "10992/10992 [==============================] - 1s 63us/step - loss: 3.9223 - acc: 0.6292\n",
      "Epoch 40/100\n",
      "10992/10992 [==============================] - 1s 57us/step - loss: 3.9045 - acc: 0.6249\n",
      "Epoch 41/100\n",
      "10992/10992 [==============================] - 1s 58us/step - loss: 3.8832 - acc: 0.6275\n",
      "Epoch 42/100\n",
      "10992/10992 [==============================] - 1s 57us/step - loss: 3.8824 - acc: 0.6275\n",
      "Epoch 43/100\n",
      "10992/10992 [==============================] - 1s 58us/step - loss: 3.8359 - acc: 0.6320\n",
      "Epoch 44/100\n",
      "10992/10992 [==============================] - 1s 67us/step - loss: 3.8334 - acc: 0.6263\n",
      "Epoch 45/100\n",
      "10992/10992 [==============================] - 1s 93us/step - loss: 3.8256 - acc: 0.6289\n",
      "Epoch 46/100\n",
      "10992/10992 [==============================] - 1s 84us/step - loss: 3.8074 - acc: 0.6354\n",
      "Epoch 47/100\n",
      "10992/10992 [==============================] - 1s 93us/step - loss: 3.9227 - acc: 0.6259\n",
      "Epoch 48/100\n",
      "10992/10992 [==============================] - 1s 87us/step - loss: 3.8041 - acc: 0.6341\n",
      "Epoch 49/100\n",
      "10992/10992 [==============================] - 1s 75us/step - loss: 3.7926 - acc: 0.6336\n",
      "Epoch 50/100\n",
      "10992/10992 [==============================] - 1s 74us/step - loss: 3.7731 - acc: 0.6316\n",
      "Epoch 51/100\n",
      "10992/10992 [==============================] - 1s 86us/step - loss: 3.7673 - acc: 0.6329\n",
      "Epoch 52/100\n",
      "10992/10992 [==============================] - 1s 86us/step - loss: 3.7713 - acc: 0.6335\n",
      "Epoch 53/100\n",
      "10992/10992 [==============================] - 1s 76us/step - loss: 3.7532 - acc: 0.6321\n",
      "Epoch 54/100\n",
      "10992/10992 [==============================] - 1s 78us/step - loss: 3.7405 - acc: 0.6386\n",
      "Epoch 55/100\n",
      "10992/10992 [==============================] - 1s 79us/step - loss: 3.7215 - acc: 0.6339\n",
      "Epoch 56/100\n",
      "10992/10992 [==============================] - 1s 74us/step - loss: 3.7029 - acc: 0.6372\n",
      "Epoch 57/100\n",
      "10992/10992 [==============================] - 1s 76us/step - loss: 3.6918 - acc: 0.6376\n",
      "Epoch 58/100\n",
      "10992/10992 [==============================] - 1s 72us/step - loss: 3.7058 - acc: 0.6401\n",
      "Epoch 59/100\n",
      "10992/10992 [==============================] - 1s 70us/step - loss: 3.6756 - acc: 0.6376\n",
      "Epoch 60/100\n",
      "10992/10992 [==============================] - 1s 73us/step - loss: 3.6695 - acc: 0.6386\n",
      "Epoch 61/100\n",
      "10992/10992 [==============================] - 1s 70us/step - loss: 3.6678 - acc: 0.6345\n",
      "Epoch 62/100\n",
      "10992/10992 [==============================] - 1s 73us/step - loss: 3.7464 - acc: 0.6367\n",
      "Epoch 63/100\n",
      "10992/10992 [==============================] - 1s 73us/step - loss: 3.6426 - acc: 0.6363\n",
      "Epoch 64/100\n",
      "10992/10992 [==============================] - 1s 71us/step - loss: 3.6325 - acc: 0.6344\n",
      "Epoch 65/100\n",
      "10992/10992 [==============================] - 1s 73us/step - loss: 3.6267 - acc: 0.6386\n",
      "Epoch 66/100\n",
      "10992/10992 [==============================] - 1s 71us/step - loss: 3.6105 - acc: 0.6396\n",
      "Epoch 67/100\n",
      "10992/10992 [==============================] - 1s 73us/step - loss: 3.6228 - acc: 0.6390\n",
      "Epoch 68/100\n",
      "10992/10992 [==============================] - 1s 71us/step - loss: 3.5889 - acc: 0.6353\n",
      "Epoch 69/100\n",
      "10992/10992 [==============================] - 1s 74us/step - loss: 3.5852 - acc: 0.6433\n",
      "Epoch 70/100\n",
      "10992/10992 [==============================] - 1s 71us/step - loss: 3.6142 - acc: 0.6372\n",
      "Epoch 71/100\n",
      "10992/10992 [==============================] - 1s 73us/step - loss: 3.5968 - acc: 0.6386\n",
      "Epoch 72/100\n",
      "10992/10992 [==============================] - 1s 73us/step - loss: 3.5625 - acc: 0.6413\n",
      "Epoch 73/100\n",
      "10992/10992 [==============================] - 1s 74us/step - loss: 3.5429 - acc: 0.6390\n",
      "Epoch 74/100\n",
      "10992/10992 [==============================] - 1s 72us/step - loss: 3.5560 - acc: 0.6412\n",
      "Epoch 75/100\n",
      "10992/10992 [==============================] - 1s 71us/step - loss: 3.5372 - acc: 0.6428\n",
      "Epoch 76/100\n",
      "10992/10992 [==============================] - 1s 73us/step - loss: 3.5455 - acc: 0.6386\n",
      "Epoch 77/100\n",
      "10992/10992 [==============================] - 1s 71us/step - loss: 3.5507 - acc: 0.6403\n",
      "Epoch 78/100\n",
      "10992/10992 [==============================] - 1s 73us/step - loss: 3.5159 - acc: 0.6377\n",
      "Epoch 79/100\n",
      "10992/10992 [==============================] - 1s 80us/step - loss: 3.5231 - acc: 0.6377\n",
      "Epoch 80/100\n",
      "10992/10992 [==============================] - 1s 74us/step - loss: 3.4873 - acc: 0.6456\n",
      "Epoch 81/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10992/10992 [==============================] - 1s 89us/step - loss: 3.4963 - acc: 0.6470\n",
      "Epoch 82/100\n",
      "10992/10992 [==============================] - 1s 84us/step - loss: 3.5013 - acc: 0.6417\n",
      "Epoch 83/100\n",
      "10992/10992 [==============================] - 1s 65us/step - loss: 3.4861 - acc: 0.6408\n",
      "Epoch 84/100\n",
      "10992/10992 [==============================] - 1s 74us/step - loss: 3.4988 - acc: 0.6390\n",
      "Epoch 85/100\n",
      "10992/10992 [==============================] - 1s 56us/step - loss: 3.4720 - acc: 0.6416\n",
      "Epoch 86/100\n",
      "10992/10992 [==============================] - 1s 58us/step - loss: 3.4693 - acc: 0.6418\n",
      "Epoch 87/100\n",
      "10992/10992 [==============================] - 1s 74us/step - loss: 3.4596 - acc: 0.6434\n",
      "Epoch 88/100\n",
      "10992/10992 [==============================] - 1s 70us/step - loss: 3.4601 - acc: 0.6436\n",
      "Epoch 89/100\n",
      "10992/10992 [==============================] - 1s 58us/step - loss: 3.4415 - acc: 0.6437\n",
      "Epoch 90/100\n",
      "10992/10992 [==============================] - 1s 96us/step - loss: 3.4436 - acc: 0.6410\n",
      "Epoch 91/100\n",
      "10992/10992 [==============================] - 1s 88us/step - loss: 3.4358 - acc: 0.6474\n",
      "Epoch 92/100\n",
      "10992/10992 [==============================] - 1s 104us/step - loss: 3.4485 - acc: 0.6441\n",
      "Epoch 93/100\n",
      "10992/10992 [==============================] - 1s 76us/step - loss: 3.4461 - acc: 0.6420\n",
      "Epoch 94/100\n",
      "10992/10992 [==============================] - 1s 95us/step - loss: 3.4410 - acc: 0.6413\n",
      "Epoch 95/100\n",
      "10992/10992 [==============================] - 1s 88us/step - loss: 3.4182 - acc: 0.6478\n",
      "Epoch 96/100\n",
      "10992/10992 [==============================] - 1s 97us/step - loss: 3.4150 - acc: 0.6459\n",
      "Epoch 97/100\n",
      "10992/10992 [==============================] - 1s 87us/step - loss: 3.4088 - acc: 0.6421\n",
      "Epoch 98/100\n",
      "10992/10992 [==============================] - 1s 87us/step - loss: 3.4031 - acc: 0.6473\n",
      "Epoch 99/100\n",
      "10992/10992 [==============================] - 1s 110us/step - loss: 3.4066 - acc: 0.6468\n",
      "Epoch 100/100\n",
      "10992/10992 [==============================] - 1s 75us/step - loss: 3.3877 - acc: 0.6477\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "# Single layer, no note info\n",
    "model_s_n = keras.Sequential()\n",
    "model_s_n.add(keras.layers.Dense(units=out.shape[1]-1, activation='relu',input_dim=X_n.shape[1]))\n",
    "model_s_n.add(keras.layers.Dense(units=out.shape[1]-1, activation='softmax'))\n",
    "model_s_n.compile(loss='categorical_crossentropy', optimizer='sgd',metrics=['accuracy'])\n",
    "model_s_n.fit(X_train_n,y_train_n,epochs=100, batch_size=32)\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "10992/10992 [==============================] - 1s 114us/step - loss: 9.4737 - acc: 0.0604\n",
      "Epoch 2/100\n",
      "10992/10992 [==============================] - 1s 78us/step - loss: 8.8723 - acc: 0.1840\n",
      "Epoch 3/100\n",
      "10992/10992 [==============================] - 1s 72us/step - loss: 8.0388 - acc: 0.3176\n",
      "Epoch 4/100\n",
      "10992/10992 [==============================] - 1s 79us/step - loss: 7.3362 - acc: 0.4203\n",
      "Epoch 5/100\n",
      "10992/10992 [==============================] - 1s 76us/step - loss: 6.7951 - acc: 0.4804\n",
      "Epoch 6/100\n",
      "10992/10992 [==============================] - 1s 76us/step - loss: 6.4128 - acc: 0.5182\n",
      "Epoch 7/100\n",
      "10992/10992 [==============================] - 1s 94us/step - loss: 6.1067 - acc: 0.5522\n",
      "Epoch 8/100\n",
      "10992/10992 [==============================] - 1s 88us/step - loss: 5.8594 - acc: 0.5622\n",
      "Epoch 9/100\n",
      "10992/10992 [==============================] - 1s 87us/step - loss: 5.6629 - acc: 0.5756\n",
      "Epoch 10/100\n",
      "10992/10992 [==============================] - 1s 96us/step - loss: 5.4878 - acc: 0.5882\n",
      "Epoch 11/100\n",
      "10992/10992 [==============================] - 1s 92us/step - loss: 5.3753 - acc: 0.5948\n",
      "Epoch 12/100\n",
      "10992/10992 [==============================] - 1s 99us/step - loss: 5.2315 - acc: 0.6074\n",
      "Epoch 13/100\n",
      "10992/10992 [==============================] - 1s 88us/step - loss: 5.1415 - acc: 0.6052\n",
      "Epoch 14/100\n",
      "10992/10992 [==============================] - 1s 78us/step - loss: 5.0501 - acc: 0.6166\n",
      "Epoch 15/100\n",
      "10992/10992 [==============================] - 1s 78us/step - loss: 4.9826 - acc: 0.6235\n",
      "Epoch 16/100\n",
      "10992/10992 [==============================] - 1s 83us/step - loss: 4.9004 - acc: 0.6279\n",
      "Epoch 17/100\n",
      "10992/10992 [==============================] - 1s 77us/step - loss: 4.8547 - acc: 0.6314\n",
      "Epoch 18/100\n",
      "10992/10992 [==============================] - 1s 76us/step - loss: 4.7980 - acc: 0.6350\n",
      "Epoch 19/100\n",
      "10992/10992 [==============================] - 1s 77us/step - loss: 4.7432 - acc: 0.6366\n",
      "Epoch 20/100\n",
      "10992/10992 [==============================] - 1s 79us/step - loss: 4.7041 - acc: 0.6390\n",
      "Epoch 21/100\n",
      "10992/10992 [==============================] - 1s 80us/step - loss: 4.6517 - acc: 0.6402\n",
      "Epoch 22/100\n",
      "10992/10992 [==============================] - 1s 79us/step - loss: 4.6224 - acc: 0.6420\n",
      "Epoch 23/100\n",
      "10992/10992 [==============================] - 1s 79us/step - loss: 4.5837 - acc: 0.6464\n",
      "Epoch 24/100\n",
      "10992/10992 [==============================] - 1s 109us/step - loss: 4.5286 - acc: 0.6511\n",
      "Epoch 25/100\n",
      "10992/10992 [==============================] - 1s 100us/step - loss: 4.4990 - acc: 0.6553\n",
      "Epoch 26/100\n",
      "10992/10992 [==============================] - 1s 72us/step - loss: 4.4770 - acc: 0.6497\n",
      "Epoch 27/100\n",
      "10992/10992 [==============================] - 1s 72us/step - loss: 4.4117 - acc: 0.6577\n",
      "Epoch 28/100\n",
      "10992/10992 [==============================] - 1s 68us/step - loss: 4.4123 - acc: 0.6587\n",
      "Epoch 29/100\n",
      "10992/10992 [==============================] - 1s 74us/step - loss: 4.3667 - acc: 0.6586\n",
      "Epoch 30/100\n",
      "10992/10992 [==============================] - 1s 62us/step - loss: 4.3412 - acc: 0.6622\n",
      "Epoch 31/100\n",
      "10992/10992 [==============================] - 1s 65us/step - loss: 4.3172 - acc: 0.6599\n",
      "Epoch 32/100\n",
      "10992/10992 [==============================] - 1s 88us/step - loss: 4.3124 - acc: 0.6626\n",
      "Epoch 33/100\n",
      "10992/10992 [==============================] - 1s 59us/step - loss: 4.2965 - acc: 0.6645\n",
      "Epoch 34/100\n",
      "10992/10992 [==============================] - 1s 65us/step - loss: 4.2589 - acc: 0.6645\n",
      "Epoch 35/100\n",
      "10992/10992 [==============================] - 1s 61us/step - loss: 4.2448 - acc: 0.6662\n",
      "Epoch 36/100\n",
      "10992/10992 [==============================] - 1s 58us/step - loss: 4.2147 - acc: 0.6685\n",
      "Epoch 37/100\n",
      "10992/10992 [==============================] - 1s 64us/step - loss: 4.1917 - acc: 0.6654\n",
      "Epoch 38/100\n",
      "10992/10992 [==============================] - 1s 77us/step - loss: 4.2056 - acc: 0.6719\n",
      "Epoch 39/100\n",
      "10992/10992 [==============================] - 1s 75us/step - loss: 4.1527 - acc: 0.6679\n",
      "Epoch 40/100\n",
      "10992/10992 [==============================] - 1s 71us/step - loss: 4.1353 - acc: 0.6759\n",
      "Epoch 41/100\n",
      "10992/10992 [==============================] - 1s 87us/step - loss: 4.1284 - acc: 0.6734\n",
      "Epoch 42/100\n",
      "10992/10992 [==============================] - 1s 88us/step - loss: 4.1148 - acc: 0.6726\n",
      "Epoch 43/100\n",
      "10992/10992 [==============================] - 1s 75us/step - loss: 4.0773 - acc: 0.6773\n",
      "Epoch 44/100\n",
      "10992/10992 [==============================] - 1s 69us/step - loss: 4.0861 - acc: 0.6778\n",
      "Epoch 45/100\n",
      "10992/10992 [==============================] - 1s 75us/step - loss: 4.0543 - acc: 0.6772\n",
      "Epoch 46/100\n",
      "10992/10992 [==============================] - 1s 99us/step - loss: 4.0432 - acc: 0.6816\n",
      "Epoch 47/100\n",
      "10992/10992 [==============================] - 1s 76us/step - loss: 4.0052 - acc: 0.6811\n",
      "Epoch 48/100\n",
      "10992/10992 [==============================] - 1s 58us/step - loss: 3.9888 - acc: 0.6827\n",
      "Epoch 49/100\n",
      "10992/10992 [==============================] - 1s 74us/step - loss: 3.9960 - acc: 0.6776\n",
      "Epoch 50/100\n",
      "10992/10992 [==============================] - 1s 71us/step - loss: 3.9859 - acc: 0.6817\n",
      "Epoch 51/100\n",
      "10992/10992 [==============================] - 1s 103us/step - loss: 3.9570 - acc: 0.6815\n",
      "Epoch 52/100\n",
      "10992/10992 [==============================] - 1s 89us/step - loss: 3.9520 - acc: 0.6817\n",
      "Epoch 53/100\n",
      "10992/10992 [==============================] - 1s 91us/step - loss: 3.9459 - acc: 0.6848\n",
      "Epoch 54/100\n",
      "10992/10992 [==============================] - 1s 104us/step - loss: 3.9321 - acc: 0.6838\n",
      "Epoch 55/100\n",
      "10992/10992 [==============================] - 1s 92us/step - loss: 3.8922 - acc: 0.6871\n",
      "Epoch 56/100\n",
      "10992/10992 [==============================] - 1s 93us/step - loss: 3.8977 - acc: 0.6827\n",
      "Epoch 57/100\n",
      "10992/10992 [==============================] - 1s 68us/step - loss: 3.9199 - acc: 0.6883\n",
      "Epoch 58/100\n",
      "10992/10992 [==============================] - 1s 64us/step - loss: 3.8782 - acc: 0.6850\n",
      "Epoch 59/100\n",
      "10992/10992 [==============================] - 1s 62us/step - loss: 3.8677 - acc: 0.6855\n",
      "Epoch 60/100\n",
      "10992/10992 [==============================] - 1s 114us/step - loss: 3.8586 - acc: 0.6870\n",
      "Epoch 61/100\n",
      "10992/10992 [==============================] - 1s 114us/step - loss: 3.8545 - acc: 0.6872\n",
      "Epoch 62/100\n",
      "10992/10992 [==============================] - 1s 84us/step - loss: 3.8724 - acc: 0.6855\n",
      "Epoch 63/100\n",
      "10992/10992 [==============================] - 1s 59us/step - loss: 3.8293 - acc: 0.6894\n",
      "Epoch 64/100\n",
      "10992/10992 [==============================] - 1s 80us/step - loss: 3.8202 - acc: 0.6869\n",
      "Epoch 65/100\n",
      "10992/10992 [==============================] - 1s 111us/step - loss: 3.8002 - acc: 0.6887\n",
      "Epoch 66/100\n",
      "10992/10992 [==============================] - 1s 97us/step - loss: 3.7977 - acc: 0.6897\n",
      "Epoch 67/100\n",
      "10992/10992 [==============================] - 1s 87us/step - loss: 3.7946 - acc: 0.6896\n",
      "Epoch 68/100\n",
      "10992/10992 [==============================] - 1s 75us/step - loss: 3.7943 - acc: 0.6913\n",
      "Epoch 69/100\n",
      "10992/10992 [==============================] - 1s 101us/step - loss: 3.7614 - acc: 0.6937\n",
      "Epoch 70/100\n",
      "10992/10992 [==============================] - 1s 104us/step - loss: 3.7727 - acc: 0.6907\n",
      "Epoch 71/100\n",
      "10992/10992 [==============================] - 1s 87us/step - loss: 3.7588 - acc: 0.6871\n",
      "Epoch 72/100\n",
      "10992/10992 [==============================] - 1s 91us/step - loss: 3.7455 - acc: 0.6889\n",
      "Epoch 73/100\n",
      "10992/10992 [==============================] - 1s 106us/step - loss: 3.7341 - acc: 0.6899\n",
      "Epoch 74/100\n",
      "10992/10992 [==============================] - 1s 81us/step - loss: 3.7258 - acc: 0.6908\n",
      "Epoch 75/100\n",
      "10992/10992 [==============================] - 1s 98us/step - loss: 3.7087 - acc: 0.6931\n",
      "Epoch 76/100\n",
      "10992/10992 [==============================] - 1s 85us/step - loss: 3.7123 - acc: 0.6926\n",
      "Epoch 77/100\n",
      "10992/10992 [==============================] - 1s 87us/step - loss: 3.7075 - acc: 0.6905\n",
      "Epoch 78/100\n",
      "10992/10992 [==============================] - 1s 62us/step - loss: 3.6993 - acc: 0.6930\n",
      "Epoch 79/100\n",
      "10992/10992 [==============================] - 1s 73us/step - loss: 3.6997 - acc: 0.6893\n",
      "Epoch 80/100\n",
      "10992/10992 [==============================] - 1s 59us/step - loss: 3.6749 - acc: 0.6946\n",
      "Epoch 81/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10992/10992 [==============================] - 1s 59us/step - loss: 3.6953 - acc: 0.6955\n",
      "Epoch 82/100\n",
      "10992/10992 [==============================] - 1s 73us/step - loss: 3.6778 - acc: 0.6929\n",
      "Epoch 83/100\n",
      "10992/10992 [==============================] - 1s 82us/step - loss: 3.6594 - acc: 0.6933\n",
      "Epoch 84/100\n",
      "10992/10992 [==============================] - 1s 64us/step - loss: 3.6438 - acc: 0.6927\n",
      "Epoch 85/100\n",
      "10992/10992 [==============================] - 1s 71us/step - loss: 3.6546 - acc: 0.6999\n",
      "Epoch 86/100\n",
      "10992/10992 [==============================] - 1s 80us/step - loss: 3.6346 - acc: 0.6914\n",
      "Epoch 87/100\n",
      "10992/10992 [==============================] - 1s 110us/step - loss: 3.6443 - acc: 0.6935\n",
      "Epoch 88/100\n",
      "10992/10992 [==============================] - 1s 61us/step - loss: 3.6245 - acc: 0.6976\n",
      "Epoch 89/100\n",
      "10992/10992 [==============================] - 1s 59us/step - loss: 3.6194 - acc: 0.6945\n",
      "Epoch 90/100\n",
      "10992/10992 [==============================] - 1s 61us/step - loss: 3.6281 - acc: 0.6960\n",
      "Epoch 91/100\n",
      "10992/10992 [==============================] - 1s 61us/step - loss: 3.6014 - acc: 0.6977\n",
      "Epoch 92/100\n",
      "10992/10992 [==============================] - 1s 59us/step - loss: 3.6169 - acc: 0.6982\n",
      "Epoch 93/100\n",
      "10992/10992 [==============================] - 1s 59us/step - loss: 3.6016 - acc: 0.6936\n",
      "Epoch 94/100\n",
      "10992/10992 [==============================] - 1s 58us/step - loss: 3.5802 - acc: 0.7006\n",
      "Epoch 95/100\n",
      "10992/10992 [==============================] - 1s 60us/step - loss: 3.5837 - acc: 0.7011\n",
      "Epoch 96/100\n",
      "10992/10992 [==============================] - 1s 60us/step - loss: 3.5722 - acc: 0.6976\n",
      "Epoch 97/100\n",
      "10992/10992 [==============================] - 1s 63us/step - loss: 3.5683 - acc: 0.6945\n",
      "Epoch 98/100\n",
      "10992/10992 [==============================] - 1s 58us/step - loss: 3.5656 - acc: 0.6956\n",
      "Epoch 99/100\n",
      "10992/10992 [==============================] - 1s 59us/step - loss: 3.5613 - acc: 0.6986\n",
      "Epoch 100/100\n",
      "10992/10992 [==============================] - 1s 56us/step - loss: 3.5535 - acc: 0.6941\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "# Single layer, with empty\n",
    "model_s_e = keras.Sequential()\n",
    "model_s_e.add(keras.layers.Dense(units=out.shape[1], activation='relu',input_dim=X_e.shape[1]))\n",
    "model_s_e.add(keras.layers.Dense(units=out.shape[1], activation='softmax'))\n",
    "model_s_e.compile(loss='categorical_crossentropy', optimizer='sgd',metrics=['accuracy'])\n",
    "model_s_e.fit(X_train_e,y_train_e,epochs=100, batch_size=32)\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "10992/10992 [==============================] - 1s 81us/step - loss: 12.6042 - acc: 0.0021\n",
      "Epoch 2/100\n",
      "10992/10992 [==============================] - 1s 64us/step - loss: 11.5191 - acc: 0.0346\n",
      "Epoch 3/100\n",
      "10992/10992 [==============================] - 1s 59us/step - loss: 10.6527 - acc: 0.1337\n",
      "Epoch 4/100\n",
      "10992/10992 [==============================] - 1s 58us/step - loss: 10.0228 - acc: 0.2011\n",
      "Epoch 5/100\n",
      "10992/10992 [==============================] - 1s 59us/step - loss: 9.5531 - acc: 0.2533\n",
      "Epoch 6/100\n",
      "10992/10992 [==============================] - 1s 60us/step - loss: 9.1892 - acc: 0.2908\n",
      "Epoch 7/100\n",
      "10992/10992 [==============================] - 1s 59us/step - loss: 8.8985 - acc: 0.3256\n",
      "Epoch 8/100\n",
      "10992/10992 [==============================] - 1s 59us/step - loss: 8.6937 - acc: 0.3439\n",
      "Epoch 9/100\n",
      "10992/10992 [==============================] - 1s 61us/step - loss: 8.4706 - acc: 0.3624\n",
      "Epoch 10/100\n",
      "10992/10992 [==============================] - 1s 58us/step - loss: 8.3275 - acc: 0.3784\n",
      "Epoch 11/100\n",
      "10992/10992 [==============================] - 1s 59us/step - loss: 8.1858 - acc: 0.3850\n",
      "Epoch 12/100\n",
      "10992/10992 [==============================] - 1s 60us/step - loss: 8.0580 - acc: 0.3919\n",
      "Epoch 13/100\n",
      "10992/10992 [==============================] - 1s 62us/step - loss: 7.9764 - acc: 0.3957\n",
      "Epoch 14/100\n",
      "10992/10992 [==============================] - 1s 99us/step - loss: 7.8702 - acc: 0.3977\n",
      "Epoch 15/100\n",
      "10992/10992 [==============================] - 1s 65us/step - loss: 7.8036 - acc: 0.4068\n",
      "Epoch 16/100\n",
      "10992/10992 [==============================] - 1s 61us/step - loss: 7.7443 - acc: 0.4120\n",
      "Epoch 17/100\n",
      "10992/10992 [==============================] - 1s 58us/step - loss: 7.6509 - acc: 0.4133\n",
      "Epoch 18/100\n",
      "10992/10992 [==============================] - 1s 64us/step - loss: 7.5717 - acc: 0.4109\n",
      "Epoch 19/100\n",
      "10992/10992 [==============================] - 1s 99us/step - loss: 7.5614 - acc: 0.4151\n",
      "Epoch 20/100\n",
      "10992/10992 [==============================] - 1s 78us/step - loss: 7.4947 - acc: 0.4199\n",
      "Epoch 21/100\n",
      "10992/10992 [==============================] - 1s 74us/step - loss: 7.4311 - acc: 0.4228\n",
      "Epoch 22/100\n",
      "10992/10992 [==============================] - 1s 81us/step - loss: 7.3900 - acc: 0.4185\n",
      "Epoch 23/100\n",
      "10992/10992 [==============================] - 1s 107us/step - loss: 7.3541 - acc: 0.4196\n",
      "Epoch 24/100\n",
      "10992/10992 [==============================] - 1s 120us/step - loss: 7.2956 - acc: 0.4240\n",
      "Epoch 25/100\n",
      "10992/10992 [==============================] - 1s 88us/step - loss: 7.2749 - acc: 0.4218\n",
      "Epoch 26/100\n",
      "10992/10992 [==============================] - 1s 88us/step - loss: 7.2419 - acc: 0.4220\n",
      "Epoch 27/100\n",
      "10992/10992 [==============================] - 1s 98us/step - loss: 7.2182 - acc: 0.4305\n",
      "Epoch 28/100\n",
      "10992/10992 [==============================] - 1s 103us/step - loss: 7.1644 - acc: 0.4272\n",
      "Epoch 29/100\n",
      "10992/10992 [==============================] - 1s 88us/step - loss: 7.1559 - acc: 0.4221\n",
      "Epoch 30/100\n",
      "10992/10992 [==============================] - 1s 97us/step - loss: 7.1183 - acc: 0.4329\n",
      "Epoch 31/100\n",
      "10992/10992 [==============================] - 1s 119us/step - loss: 7.0933 - acc: 0.4301\n",
      "Epoch 32/100\n",
      "10992/10992 [==============================] - 1s 96us/step - loss: 7.0532 - acc: 0.4320\n",
      "Epoch 33/100\n",
      "10992/10992 [==============================] - 1s 76us/step - loss: 7.0355 - acc: 0.4329\n",
      "Epoch 34/100\n",
      "10992/10992 [==============================] - 1s 66us/step - loss: 7.0162 - acc: 0.4307\n",
      "Epoch 35/100\n",
      "10992/10992 [==============================] - 1s 74us/step - loss: 6.9868 - acc: 0.4312\n",
      "Epoch 36/100\n",
      "10992/10992 [==============================] - 1s 99us/step - loss: 6.9385 - acc: 0.4353\n",
      "Epoch 37/100\n",
      "10992/10992 [==============================] - 1s 104us/step - loss: 6.9377 - acc: 0.4346\n",
      "Epoch 38/100\n",
      "10992/10992 [==============================] - 1s 94us/step - loss: 6.9063 - acc: 0.4330\n",
      "Epoch 39/100\n",
      "10992/10992 [==============================] - 1s 83us/step - loss: 6.8749 - acc: 0.4388\n",
      "Epoch 40/100\n",
      "10992/10992 [==============================] - 1s 79us/step - loss: 6.8794 - acc: 0.4320\n",
      "Epoch 41/100\n",
      "10992/10992 [==============================] - 1s 79us/step - loss: 6.8499 - acc: 0.4339\n",
      "Epoch 42/100\n",
      "10992/10992 [==============================] - 1s 94us/step - loss: 6.8143 - acc: 0.4331\n",
      "Epoch 43/100\n",
      "10992/10992 [==============================] - 1s 99us/step - loss: 6.7903 - acc: 0.4378\n",
      "Epoch 44/100\n",
      "10992/10992 [==============================] - 1s 121us/step - loss: 6.7797 - acc: 0.4343\n",
      "Epoch 45/100\n",
      "10992/10992 [==============================] - 1s 85us/step - loss: 6.7607 - acc: 0.4347\n",
      "Epoch 46/100\n",
      "10992/10992 [==============================] - 1s 78us/step - loss: 6.7625 - acc: 0.4351\n",
      "Epoch 47/100\n",
      "10992/10992 [==============================] - 1s 76us/step - loss: 6.7154 - acc: 0.4354\n",
      "Epoch 48/100\n",
      "10992/10992 [==============================] - 1s 77us/step - loss: 6.7037 - acc: 0.4459\n",
      "Epoch 49/100\n",
      "10992/10992 [==============================] - 1s 77us/step - loss: 6.6767 - acc: 0.4446\n",
      "Epoch 50/100\n",
      "10992/10992 [==============================] - 1s 91us/step - loss: 6.6934 - acc: 0.4429\n",
      "Epoch 51/100\n",
      "10992/10992 [==============================] - 1s 84us/step - loss: 6.6621 - acc: 0.4356\n",
      "Epoch 52/100\n",
      "10992/10992 [==============================] - 1s 96us/step - loss: 6.6384 - acc: 0.4393\n",
      "Epoch 53/100\n",
      "10992/10992 [==============================] - 1s 112us/step - loss: 6.6288 - acc: 0.4400\n",
      "Epoch 54/100\n",
      "10992/10992 [==============================] - 1s 99us/step - loss: 6.6159 - acc: 0.4374\n",
      "Epoch 55/100\n",
      "10992/10992 [==============================] - 1s 100us/step - loss: 6.6000 - acc: 0.4420\n",
      "Epoch 56/100\n",
      "10992/10992 [==============================] - 1s 101us/step - loss: 6.5824 - acc: 0.4389\n",
      "Epoch 57/100\n",
      "10992/10992 [==============================] - 1s 118us/step - loss: 6.5651 - acc: 0.4422\n",
      "Epoch 58/100\n",
      "10992/10992 [==============================] - 1s 92us/step - loss: 6.5558 - acc: 0.4378\n",
      "Epoch 59/100\n",
      "10992/10992 [==============================] - 1s 74us/step - loss: 6.5375 - acc: 0.4434\n",
      "Epoch 60/100\n",
      "10992/10992 [==============================] - 1s 85us/step - loss: 6.5437 - acc: 0.4382\n",
      "Epoch 61/100\n",
      "10992/10992 [==============================] - 1s 77us/step - loss: 6.5137 - acc: 0.4416\n",
      "Epoch 62/100\n",
      "10992/10992 [==============================] - 1s 87us/step - loss: 6.4964 - acc: 0.4390\n",
      "Epoch 63/100\n",
      "10992/10992 [==============================] - 1s 89us/step - loss: 6.4832 - acc: 0.4438\n",
      "Epoch 64/100\n",
      "10992/10992 [==============================] - 1s 89us/step - loss: 6.4784 - acc: 0.4409\n",
      "Epoch 65/100\n",
      "10992/10992 [==============================] - 1s 86us/step - loss: 6.4689 - acc: 0.4416\n",
      "Epoch 66/100\n",
      "10992/10992 [==============================] - 1s 102us/step - loss: 6.4776 - acc: 0.4413\n",
      "Epoch 67/100\n",
      "10992/10992 [==============================] - 1s 97us/step - loss: 6.4390 - acc: 0.4461\n",
      "Epoch 68/100\n",
      "10992/10992 [==============================] - 1s 88us/step - loss: 6.4395 - acc: 0.4377\n",
      "Epoch 69/100\n",
      "10992/10992 [==============================] - 1s 89us/step - loss: 6.4254 - acc: 0.4424\n",
      "Epoch 70/100\n",
      "10992/10992 [==============================] - 1s 89us/step - loss: 6.3840 - acc: 0.4363\n",
      "Epoch 71/100\n",
      "10992/10992 [==============================] - 1s 105us/step - loss: 6.4050 - acc: 0.4384\n",
      "Epoch 72/100\n",
      "10992/10992 [==============================] - 1s 88us/step - loss: 6.3967 - acc: 0.4430\n",
      "Epoch 73/100\n",
      "10992/10992 [==============================] - 1s 105us/step - loss: 6.3939 - acc: 0.4402\n",
      "Epoch 74/100\n",
      "10992/10992 [==============================] - 1s 81us/step - loss: 6.3701 - acc: 0.4469\n",
      "Epoch 75/100\n",
      "10992/10992 [==============================] - 1s 83us/step - loss: 6.3483 - acc: 0.4467\n",
      "Epoch 76/100\n",
      "10992/10992 [==============================] - 1s 83us/step - loss: 6.3561 - acc: 0.4426\n",
      "Epoch 77/100\n",
      "10992/10992 [==============================] - 1s 100us/step - loss: 6.3259 - acc: 0.4413\n",
      "Epoch 78/100\n",
      "10992/10992 [==============================] - 1s 89us/step - loss: 6.3105 - acc: 0.4428\n",
      "Epoch 79/100\n",
      "10992/10992 [==============================] - 1s 82us/step - loss: 6.3128 - acc: 0.4428\n",
      "Epoch 80/100\n",
      "10992/10992 [==============================] - 1s 84us/step - loss: 6.3041 - acc: 0.4470\n",
      "Epoch 81/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10992/10992 [==============================] - 1s 86us/step - loss: 6.3032 - acc: 0.4420\n",
      "Epoch 82/100\n",
      "10992/10992 [==============================] - 1s 74us/step - loss: 6.2879 - acc: 0.4452\n",
      "Epoch 83/100\n",
      "10992/10992 [==============================] - 1s 80us/step - loss: 6.2681 - acc: 0.4441\n",
      "Epoch 84/100\n",
      "10992/10992 [==============================] - 1s 76us/step - loss: 6.2520 - acc: 0.4464\n",
      "Epoch 85/100\n",
      "10992/10992 [==============================] - 1s 76us/step - loss: 6.2693 - acc: 0.4404\n",
      "Epoch 86/100\n",
      "10992/10992 [==============================] - 1s 77us/step - loss: 6.2617 - acc: 0.4409\n",
      "Epoch 87/100\n",
      "10992/10992 [==============================] - 1s 79us/step - loss: 6.2539 - acc: 0.4476\n",
      "Epoch 88/100\n",
      "10992/10992 [==============================] - 1s 77us/step - loss: 6.2291 - acc: 0.4430\n",
      "Epoch 89/100\n",
      "10992/10992 [==============================] - 1s 79us/step - loss: 6.2200 - acc: 0.4430\n",
      "Epoch 90/100\n",
      "10992/10992 [==============================] - 1s 82us/step - loss: 6.2408 - acc: 0.4419\n",
      "Epoch 91/100\n",
      "10992/10992 [==============================] - 1s 78us/step - loss: 6.1981 - acc: 0.4401\n",
      "Epoch 92/100\n",
      "10992/10992 [==============================] - 1s 81us/step - loss: 6.2070 - acc: 0.4455\n",
      "Epoch 93/100\n",
      "10992/10992 [==============================] - 1s 80us/step - loss: 6.1906 - acc: 0.4432\n",
      "Epoch 94/100\n",
      "10992/10992 [==============================] - 1s 81us/step - loss: 6.1758 - acc: 0.4483\n",
      "Epoch 95/100\n",
      "10992/10992 [==============================] - 1s 80us/step - loss: 6.1784 - acc: 0.4477\n",
      "Epoch 96/100\n",
      "10992/10992 [==============================] - 1s 80us/step - loss: 6.1709 - acc: 0.4451\n",
      "Epoch 97/100\n",
      "10992/10992 [==============================] - 1s 76us/step - loss: 6.1728 - acc: 0.4487\n",
      "Epoch 98/100\n",
      "10992/10992 [==============================] - 1s 81us/step - loss: 6.1547 - acc: 0.4473\n",
      "Epoch 99/100\n",
      "10992/10992 [==============================] - 1s 79us/step - loss: 6.1478 - acc: 0.4441\n",
      "Epoch 100/100\n",
      "10992/10992 [==============================] - 1s 79us/step - loss: 6.1202 - acc: 0.4451\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f6480559b00>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Single layer, one hot encoding for notes\n",
    "model_s_h = keras.Sequential()\n",
    "model_s_h.add(keras.layers.Dense(units=y_h.shape[1], activation='relu',input_dim=X_h.shape[1]))\n",
    "model_s_h.add(keras.layers.Dense(units=y_h.shape[1], activation='softmax'))\n",
    "model_s_h.compile(loss='categorical_crossentropy', optimizer='sgd',metrics=['accuracy'])\n",
    "model_s_h.fit(X_train_h,y_train_h,epochs=100, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_n = model_s_n.predict(X_test_n,batch_size=32)\n",
    "y_pred_e = model_s_e.predict(X_test_e,batch_size=32)\n",
    "y_pred_h = model_s_h.predict(X_test_h,batch_size=32)\n",
    "threshold = 0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General Accuracy\n",
    "def general_acc(y_pred,y_true):\n",
    "    j=0\n",
    "    for i in range(y_true.shape[0]):\n",
    "        if (np.array_equal(y_pred[i,:],y_true[i,:])):\n",
    "            j=j+1\n",
    "    return (j/y_true.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Empty Accuracy\n",
    "def empty_acc(y_pred,y_true):\n",
    "    j=0\n",
    "    k=0\n",
    "    z=np.zeros(88)\n",
    "    for i in range(y_true.shape[0]):\n",
    "        if (np.array_equal(y_pred[i,:],z)):\n",
    "            k=k+1\n",
    "            if (np.array_equal(y_true[i],z)):\n",
    "                j=j+1\n",
    "    return (j/k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Non Empty Accuracy\n",
    "def non_empty_acc(y_pred,y_true):\n",
    "    j=0\n",
    "    k=0\n",
    "    z=np.zeros(88)\n",
    "    for i in range(y_true.shape[0]):\n",
    "        if (not np.array_equal(y_pred[i,:],z)):\n",
    "            k=k+1\n",
    "            if (np.array_equal(y_true[i,:],y_pred[i,:])):\n",
    "                j=j+1\n",
    "    return (j/k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of Notes Accuracy\n",
    "def note_num_acc(y_pred,y_true):\n",
    "    j=0\n",
    "    a=np.sum(y_pred,axis=1)\n",
    "    b=np.sum(y_true,axis=1)\n",
    "    for i in range(y_true.shape[0]):\n",
    "        if (a[i]==b[i]):\n",
    "            j=j+1\n",
    "    return (j/y_true.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of Notes Accuracy by number\n",
    "def note_num_acc_specific(y_pred,y_true):\n",
    "    j=0\n",
    "    a=np.sum(y_pred,axis=1)\n",
    "    b=np.sum(y_true,axis=1)\n",
    "    c=np.unique(np.sum(y_pred,axis=1))\n",
    "    d=np.unique(np.sum(y_true,axis=1))\n",
    "    e=np.zeros(d.shape[0])\n",
    "    f=np.zeros(d.shape[0])\n",
    "    for i in range(d.shape[0]):\n",
    "        f[i]=np.where(a==i)[0].shape[0]\n",
    "        if (f[i]==0):\n",
    "            f[i]=1\n",
    "    for i in range(y_true.shape[0]):\n",
    "        num_pred_notes = int(a[i])\n",
    "        if (num_pred_notes==b[i]):\n",
    "            e[num_pred_notes]=e[num_pred_notes]+1\n",
    "    for i in range(d.shape[0]):\n",
    "        e[i]=e[i]/f[i]\n",
    "    return e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of right notes when right\n",
    "def same_num_note_acc(y_pred,y_true):\n",
    "    j=0\n",
    "    k=0\n",
    "    a=np.sum(y_pred,axis=1)\n",
    "    b=np.sum(y_true,axis=1)\n",
    "    for i in range(y_true.shape[0]):\n",
    "        if (a[i]==b[i]):\n",
    "            k=k+1\n",
    "            if (np.array_equal(y_pred[i,:],y_true[i,:])):\n",
    "                j=j+1\n",
    "    return (j/k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of correct notes in prediction\n",
    "def num_notes_correct_acc1(y_pred,y_true):\n",
    "    j=0\n",
    "    for i in range(y_true.shape[0]):\n",
    "        a=np.where(y_pred[i,:]==1)[0]\n",
    "        b=np.where(y_true[i,:]==1)[0]\n",
    "        if (a.shape[0]!=0):\n",
    "            c = np.intersect1d(a,b).shape[0]\n",
    "            j=j+c/(a.shape[0])\n",
    "    return (j/y_true.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of correct notes in prediction\n",
    "def num_notes_correct_acc2(y_pred,y_true):\n",
    "    j=0\n",
    "    for i in range(y_true.shape[0]):\n",
    "        a=np.where(y_pred[i,:]==1)[0]\n",
    "        b=np.where(y_true[i,:]==1)[0]\n",
    "        if (b.shape[0]!=0):\n",
    "            c = np.intersect1d(a,b).shape[0]\n",
    "            j=j+c/(b.shape[0])\n",
    "    return (j/y_true.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_note_pred_n = y_pred_n.copy()\n",
    "y_note_pred_n[y_note_pred_n<threshold]=0\n",
    "y_note_pred_n[y_note_pred_n>=threshold]=1\n",
    "y_note_test_n=y_test_n.get_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "General Accuracy: 0.5120087336244541\n"
     ]
    }
   ],
   "source": [
    "general_acc_n = general_acc(y_pred=y_note_pred_n,y_true=y_note_test_n)\n",
    "print('General Accuracy:',general_acc_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty Accuracy: 0.5518672199170125\n"
     ]
    }
   ],
   "source": [
    "empty_acc_n=empty_acc(y_pred=y_note_pred_n,y_true=y_note_test_n)\n",
    "print('Empty Accuracy:',empty_acc_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non Empty Accuracy: 0.5081771041084963\n"
     ]
    }
   ],
   "source": [
    "non_empty_acc_n=non_empty_acc(y_pred=y_note_pred_n,y_true=y_note_test_n)\n",
    "print('Non Empty Accuracy:', non_empty_acc_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note Number Accuracy: 0.5516739446870451\n"
     ]
    }
   ],
   "source": [
    "note_num_acc_n=note_num_acc(y_pred=y_note_pred_n,y_true=y_note_test_n)\n",
    "print('Note Number Accuracy:',note_num_acc_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note Number Accuracy of 0 : 0.5518672199170125\n",
      "Note Number Accuracy of 1 : 0.6437980241492866\n",
      "Note Number Accuracy of 2 : 0.3189522342064715\n",
      "Note Number Accuracy of 3 : 0.08333333333333333\n",
      "Note Number Accuracy of 4 : 0.0\n",
      "Note Number Accuracy of 5 : 0.0\n",
      "Note Number Accuracy of 6 : 0.0\n",
      "Note Number Accuracy of 7 : 0.0\n"
     ]
    }
   ],
   "source": [
    "note_num_acc_specific_n = note_num_acc_specific(y_pred=y_note_pred_n,y_true=y_note_test_n)\n",
    "for i in range(note_num_acc_specific_n.shape[0]):\n",
    "    print('Note Number Accuracy of',i,':',note_num_acc_specific_n[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Same Number of Notes, Accuracy: 0.9281002638522428\n"
     ]
    }
   ],
   "source": [
    "same_num_note_acc_n=same_num_note_acc(y_pred=y_note_pred_n,y_true=y_note_test_n)\n",
    "print('Same Number of Notes, Accuracy:',same_num_note_acc_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Notes correct in Prediction out of Prediction: 0.7937287724405627\n"
     ]
    }
   ],
   "source": [
    "num_notes_correct_acc_n1=num_notes_correct_acc1(y_pred=y_note_pred_n,y_true=y_note_test_n)\n",
    "print('Number of Notes correct in Prediction out of Prediction:',num_notes_correct_acc_n1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Notes correct in Prediction out of True: 0.6470489360227358\n"
     ]
    }
   ],
   "source": [
    "num_notes_correct_acc_n2=num_notes_correct_acc2(y_pred=y_note_pred_n,y_true=y_note_test_n)\n",
    "print('Number of Notes correct in Prediction out of True:',num_notes_correct_acc_n2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = y_pred_e.copy()\n",
    "threshold_pred_e = np.zeros_like(a)\n",
    "threshold_pred_e[np.arange(len(a)),a.argmax(1)]=1\n",
    "y_note_pred_e = threshold_pred_e[:,0:88]\n",
    "y_note_test_e = y_test_e.iloc[:,0:88].get_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "General Accuracy: 0.5090975254730713\n"
     ]
    }
   ],
   "source": [
    "general_acc_e = general_acc(y_pred=y_note_pred_e,y_true=y_note_test_e)\n",
    "print('General Accuracy:',general_acc_e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty Accuracy: 0.7447698744769874\n"
     ]
    }
   ],
   "source": [
    "empty_acc_e=empty_acc(y_pred=y_note_pred_e,y_true=y_note_test_e)\n",
    "print('Empty Accuracy:',empty_acc_e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non Empty Accuracy: 0.4866480669589478\n"
     ]
    }
   ],
   "source": [
    "non_empty_acc_e=non_empty_acc(y_pred=y_note_pred_e,y_true=y_note_test_e)\n",
    "print('Non Empty Accuracy:', non_empty_acc_e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note Number Accuracy: 0.5822416302765647\n"
     ]
    }
   ],
   "source": [
    "note_num_acc_e=note_num_acc(y_pred=y_note_pred_e,y_true=y_note_test_e)\n",
    "print('Note Number Accuracy:',note_num_acc_e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note Number Accuracy of 0 : 0.7447698744769874\n",
      "Note Number Accuracy of 1 : 0.5667596652052611\n",
      "Note Number Accuracy of 2 : 0.0\n",
      "Note Number Accuracy of 3 : 0.0\n",
      "Note Number Accuracy of 4 : 0.0\n",
      "Note Number Accuracy of 5 : 0.0\n",
      "Note Number Accuracy of 6 : 0.0\n",
      "Note Number Accuracy of 7 : 0.0\n"
     ]
    }
   ],
   "source": [
    "note_num_acc_specific_e = note_num_acc_specific(y_pred=y_note_pred_e,y_true=y_note_test_e)\n",
    "for i in range(note_num_acc_specific_e.shape[0]):\n",
    "    print('Note Number Accuracy of',i,':',note_num_acc_specific_e[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Same Number of Notes, Accuracy: 0.874375\n"
     ]
    }
   ],
   "source": [
    "same_num_note_acc_e=same_num_note_acc(y_pred=y_note_pred_e,y_true=y_note_test_e)\n",
    "print('Same Number of Notes, Accuracy:',same_num_note_acc_e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Notes correct in Prediction out of Prediction: 0.8249636098981077\n"
     ]
    }
   ],
   "source": [
    "num_notes_correct_acc_e1=num_notes_correct_acc1(y_pred=y_note_pred_e,y_true=y_note_test_e)\n",
    "print('Number of Notes correct in Prediction out of Prediction:',num_notes_correct_acc_e1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Notes correct in Prediction out of Prediction: 0.5740729188327445\n"
     ]
    }
   ],
   "source": [
    "num_notes_correct_acc_e2=num_notes_correct_acc2(y_pred=y_note_pred_e,y_true=y_note_test_e)\n",
    "print('Number of Notes correct in Prediction out of Prediction:',num_notes_correct_acc_e2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold_pred_h = y_pred_h.copy()[:,0:88]\n",
    "num_pred_prob = y_pred_h.copy()\n",
    "for i in range(y_test_h.shape[0]):\n",
    "    a = num_pred_prob[:,88:num_pred_prob.shape[1]]\n",
    "    num_pred=count_notes_hot.columns[np.argmax(a[i,:])]\n",
    "    pred_idx = np.flip(np.argsort(threshold_pred_h[i,:]))[0:num_pred]\n",
    "    b=np.zeros(88)\n",
    "    if (num_pred==0):\n",
    "        threshold_pred_h[i,:]=b\n",
    "    else:\n",
    "        b[pred_idx]=1\n",
    "        threshold_pred_h[i,:]=b\n",
    "        \n",
    "y_note_pred_h = threshold_pred_h[:,0:88]\n",
    "y_note_test_h = y_test_h.iloc[:,0:88].get_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "General Accuracy: 0.5473071324599709\n"
     ]
    }
   ],
   "source": [
    "general_acc_h = general_acc(y_pred=threshold_pred_h[:,0:88],y_true=y_test_h.iloc[:,0:88].get_values())\n",
    "print('General Accuracy:',general_acc_h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty Accuracy: 0.7792207792207793\n"
     ]
    }
   ],
   "source": [
    "empty_acc_h=empty_acc(y_pred=y_note_pred_h,y_true=y_note_test_h)\n",
    "print('Empty Accuracy:',empty_acc_h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non Empty Accuracy: 0.5260230433055224\n"
     ]
    }
   ],
   "source": [
    "non_empty_acc_h=non_empty_acc(y_pred=y_note_pred_h,y_true=y_note_test_h)\n",
    "print('Non Empty Accuracy:', non_empty_acc_h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note Number Accuracy: 0.6990538573508006\n"
     ]
    }
   ],
   "source": [
    "note_num_acc_h=note_num_acc(y_pred=y_note_pred_h,y_true=y_note_test_h)\n",
    "print('Note Number Accuracy:',note_num_acc_h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note Number Accuracy of 0 : 0.7792207792207793\n",
      "Note Number Accuracy of 1 : 0.8364427860696517\n",
      "Note Number Accuracy of 2 : 0.6866666666666666\n",
      "Note Number Accuracy of 3 : 0.2971014492753623\n",
      "Note Number Accuracy of 4 : 0.2129032258064516\n",
      "Note Number Accuracy of 5 : 0.3582089552238806\n",
      "Note Number Accuracy of 6 : 0.391304347826087\n",
      "Note Number Accuracy of 7 : 0.3611111111111111\n"
     ]
    }
   ],
   "source": [
    "note_num_acc_specific_h = note_num_acc_specific(y_pred=y_note_pred_h,y_true=y_note_test_h)\n",
    "for i in range(note_num_acc_specific_h.shape[0]):\n",
    "    print('Note Number Accuracy of',i,':',note_num_acc_specific_h[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Same Number of Notes, Accuracy: 0.7829255596043727\n"
     ]
    }
   ],
   "source": [
    "same_num_note_acc_h=same_num_note_acc(y_pred=y_note_pred_h,y_true=y_note_test_h)\n",
    "print('Same Number of Notes, Accuracy:',same_num_note_acc_h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Notes correct in Prediction out of Prediction: 0.7202744853399881\n"
     ]
    }
   ],
   "source": [
    "num_notes_correct_acc_h1=num_notes_correct_acc1(y_pred=y_note_pred_h,y_true=y_note_test_h)\n",
    "print('Number of Notes correct in Prediction out of Prediction:',num_notes_correct_acc_h1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Notes correct in Prediction out of Prediction: 0.6894693976571703\n"
     ]
    }
   ],
   "source": [
    "num_notes_correct_acc_h2=num_notes_correct_acc2(y_pred=y_note_pred_h,y_true=y_note_test_h)\n",
    "print('Number of Notes correct in Prediction out of Prediction:',num_notes_correct_acc_h2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
